1. Approximation Capabilities of Multilayer Feedforward Networks  
Kurt Hornik (1991)  
`https://www.sciencedirect.com/science/article/pii/089360809190009T?via%3Dihub`

2. An Unsupervised Approach to Solving Inverse Problems using Generative Adversarial Networks  
Rushil Anirudh et al  
`https://arxiv.org/abs/1805.07281`

3. Efficient Estimation of Word Representations in Latent Space  
Tomas Mikolov et al  
`https://arxiv.org/abs/1301.3781`

4. Deep Neural Networks with Random Gaussian Distributed Weights: A Universal Classification Strategy?  
Raja Giryes at al  
`https://arxiv.org/pdf/1504.08291.pdf`

5. Batch Normalisation: Accelerating Deep Network Training by Reducing Internal Covariate Shift  
Sergey Ioffe, Christian Szegedy  
`https://arxiv.org/abs/1502.03167`

6. Dropout: A Simple Way to Prevent Neural Networks from Overfitting  
Nitish Srivastava et al  
`http://jmlr.org/papers/v15/srivastava14a.html`  

7. Understanding the Disharmony between Dropout and Batch Normalisation by Variance Shift  
Xiang Li et al  
`https://arxiv.org/abs/1801.05134`

8. Regularisation for Deep Learning  
Ian Goodfellow, Yoshua Bengio, Aaron Courville  
`http://www.deeplearningbook.org/contents/regularization.html`

9. Auto-Encoding Variational Bayes  
Diederik P Kingma, Max Welling  
`https://arxiv.org/abs/1312.6114`

10. beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework  
Irina Higgins et al  
`https://openreview.net/forum?id=Sy2fzU9gl`

11. Adam: A Method for Stochastic Optimisation  
Diederik P Kingma, Jimmy Ba  
`https://arxiv.org/abs/1412.6980`

12. Neural Network Optimisation  
Renqian Luo et al  
`https://arxiv.org/pdf/1808.07233.pdf`  

\documentclass[../../main.tex]{subfiles}

\begin{document}

\chapter{Introduction}

\section{Motivation}

Many engineering challenges can be expressed as optimisation problems, in which the objective is to search a space of possibilities for a value which maximises some objective function.
In real world problems, the objective function is typically complicated enough that its maximum cannot be found analytically; in these cases, it is necessary to explore the solution space in order to find the optimal solution.
A number of algorithms exist to search this space efficiently, but often converge slowly when the error surface of the objective function changes abruptly.
This will often be the case when trying to optimise continuous constraints, such as maximising the thrust of an engine, while simultaneously adhering to binary constraints, such as avoiding degenerate geometries.

Machine learning excels in exploiting underlying patterns in data to make predictions in the face of uncertainty.
This project explores the use of machine learning algorithms in constructing a differentiable mapping between an arbitrary latent space and the space of solutions to a particular set of problems such that any point in the latent space, when mapped to the solution space, will satisfy some set of binary constraints.

\section{Engineering problems}

For the purposes of this project, an engineering problem is defined as an optimisation problem in which we must find a solution $s$ which maximises an arbitrary objective function $f(s)$, while also satisfying a given constraint $c$.
Constraint satisfaction is determined by some function $h(c, s)$ which maps a constraint and solution to one of two values, $\{\text{satisfied}, \text{unsatisfied}\}$.

The functions $f$ and $h$ are deterministic and belong to an engineering environment, which can be thought of as an idealised mathematical model of a particular real-life problem.
While each environment has a unique constraint satisfaction function $h$, which is parameterised by a constraint, an environment may define a number of different continuous objective functions for which we may like to optimise.

It is also assumed that both the solution and constraint are parameterised by a vector that is bounded by an hypercube in $m$ or $n$ dimensions respectively.
The space of valid solutions is referred to as $S$, and the space of valid constraints is referred to as $C$.
$$S = \{(s_1, ..., s_m) \; | \; s_i \in \{a_S, b_S\}, 1 \le i \le m\}$$
$$C = \{(c_1, ..., c_n) \; | \; c_j \in \{a_C, b_C\}, 1 \le j \le n\}$$
where $a$ and $b$ are the arbitrary upper and lower bounds of the hypercube in each dimension.

Since both $S$ and $C$ are hypercubes, it is trivial to take samples from them.
As such, solving an engineering problem as defined here can be broken down into two steps: finding a solution vector $s$ for which $f(s)$ is suitably large; and ensuring that $h(c, s) = \text{satisfied}$ for the given constraint $c$.

\section{Learned latent mapping}

\end{document}
